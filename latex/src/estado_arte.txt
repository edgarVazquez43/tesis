1Points Cloud----------------

Para optimizar los movimientos de un robot, no sólo se debe identificar cada objeto que se encuentra en el entorno de trabajo, sino también
Situado en referencia al propio robot. Normalmente, la segmentación de objetos de una imagen se logra mediante la segmentación de color.
Esta segmentación puede conseguirse procesando los componentes cromáticos R, G y B. Sin embargo, este método tiene la
Desventaja de haber sido muy sensible a los cambios en la iluminación. Conversión de la imagen RGB en el espacio de color CIE-Lab
Evita la falta de sensibilidad aumentando la precisión de la segmentación del color. Desafortunadamente, si varios objetos
Del mismo color se presentan en la escena, no es posible identificar uno de estos objetos utilizando sólo este espacio de color.
Por lo tanto, necesitamos considerar una fuente de datos adicional, en este caso la profundidad, para discriminar objetos que son
No en el mismo plano que el objeto de interés. En este trabajo, se introduce un algoritmo para detectar objetos, esencialmente
En ambientes interiores, utilizando CIE-Lab y técnicas de segmentación de profundidad. Procesamos las imágenes de color y profundidad
Proporcionado por el sensor Kinect para proponer una estrategia visual con un rendimiento en tiempo real.


Este proyecto se ocupa del problema de detectar objetos basados ​​en un nuevo dispositivo de detección RGB-D
Cámara: el sensor de Microsoft Kinect [8, 9]. La rápida evolución de esta reciente tecnología
Calidad de imágenes sincronizadas de color y profundidad en el rendimiento de alta frecuencia. En particular, la profundidad
La imagen se obtiene mediante una matriz proyectada por infrarrojos que rebote sobre los objetos. La cámara IR captura
Estos haces, con una varianza de intensidad, y calcula la distancia a cada objeto en la escena. Aquí nosotros
Procese la imagen de color RGB para obtener una imagen de espacio de color CIE-Lab. Luego, calculamos el euclidiano
Distancias entre un píxel seleccionado del objeto de interés y el resto de los puntos de la imagen, este
La información se interpreta como un valor de probabilidad para cada punto de la imagen en el espacio de color [10]. Desde el color
Y la información de profundidad son proporcionados por diferentes sensores dentro del kinect, una operación de homografía es
Aplicado a la imagen de probabilidad con el fin de obtener una adecuación geométrica con respecto a la imagen de profundidad.
Después de eso, combinamos información de probabilidad y profundidad para calcular la segmentación final del objeto
en escena.
Este artículo está organizado de la siguiente forma: La sección 2 describe nuestro algoritmo propuesto para la detección de objetos.
El concepto de homografía y cómo relacionar diferentes planos de imagen del conjunto de datos se presenta en sec-
3. Las ventajas y la transformación de imagen en color RGB a CIE-Lab se describen en la sección 4. La
La sección 5 describe cómo hacer la segmentación de color y profundidad seguida de algunos resultados experimentales
Y conclusiones.

5. Segmentación de la profundidad de color
En primer lugar, explicamos los resultados utilizando sólo el algoritmo de segmentación de color. La prueba consiste en varios tipos
De sillas con color diferente como se muestra en la Fig. 4.a. La imagen de color segmentada correspondiente cuando
Seleccione la silla naranja se muestra en la Fig. 4.b. Examinando esta figura, observamos que el color de la imagen seleccionada
Objeto se resalta en negro, siendo el resto de los objetos representados en escala de grises. En la Fig. 4.c muestra
El caso cuando seleccionamos la silla azul.
La imagen de color RGB mostrada en la Fig. 5.a se transforma en el espacio de color CIE-Lab como se describe
En la sección anterior. Esta transformación simplifica la segmentación del color y es sólo una cuestión de Calculando la distancia euclidiana para cada componente al punto de interés. Un ejemplo de este procedimiento
Se presenta en la Fig. 5.b, donde el punto de interés se elige en la silla media.
La imagen probabilística permite identificar todos los objetos con el mismo color. La máscara inicial es ob-
Eliminado todos los objetos para los cuales las distancias euclidianas son mayores que un umbral definido
experimentalmente. Esta máscara se presenta en la Fig. 5.c. Hasta ahora, todos los objetos del mismo color pueden ser
Se extrae de la imagen RGB aplicando la máscara inicial. Sin embargo, para obtener otra máscara que
Contiene sólo el objeto de interés, se utiliza la información de profundidad. Por lo tanto, la máscara inicial y la profundidad
Información se combinan para eliminar los objetos con diferentes colores e información geométrica
Al objeto interesante.






Manipuladores  ---- -- -- - ------------------------>

